# Deep learning Labs

Lab 1 - One-layer network to classify images from the CIFAR-10 dataset. Using mini-batch gradient descent applied to a cost function that computes the cross-entropy loss of the classifier applied to the labelled training data with L2 regularization.

Lab 2 - Two-layer network on a multi classification problem with stochastic mini batch gradient descent on CIFAR-10. Momentum is also applied to fasten the training while the aim is to minimize the loss function called cross entropy with a regularization term.  

Lab 3 - Multi-layer networks on a multi classification problem with batch normalization. Using stochastic mini batch gradient descent.

Lab 4  - RNN with adagrad using gradient descent on the book of J.K.Rowlingâ€™s goblet of fire for text generation.